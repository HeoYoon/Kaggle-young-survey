---
title: "young_survey"
author: "YOON HEO"
date: '2020 2 13 '
output: html_document
---

### library
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(MASS)
library(corrplot)
library(gridExtra)
library(qgraph)
library(igraph)
library(polycor)
library(cluster)
library(factoextra)
library('e1071')
library(caret)
library(randomForest)
select <- dplyr::select
```


## Data loading

```{r}

data <- read.csv("responses.csv", na.strings = c("", "NA", " "), stringsAsFactors = FALSE)
dim(data)
```

## Check missing value

```{r missing value, warning=FALSE, message=FALSE}

# missing_values <- data %>% 
#   summarize_all(funs(sum(is.na(.))/n()))
# missing_values <- gather(missing_values)
# 
# missing_values %>%
#   filter(value > 0) %>%
#   mutate(value <- round(value * 100,1)) %>%
#   ggplot(aes(reorder(key,value),value)) +
#   geom_bar(stat = "identity") +
#   coord_flip() + xlab("Missing Value") + ylab("") +
#   theme_bw()  

data %>%
  summarise_all(funs(sum(is.na(.)))) %>%
  gather() %>%
  filter(value > 0) %>%
  nrow()

```

## 데이터 클리닝

### 캐릭터 데이터 숫자로 바꾸기

```{r}

## 담배쟁이들
data$Smoking[data$Smoking == "never smoked" & !is.na(data$Smoking)] <- 1
data$Smoking[data$Smoking == "tried smoking" & !is.na(data$Smoking)] <- 2
data$Smoking[data$Smoking == "former smoker" & !is.na(data$Smoking)] <- 3
data$Smoking[data$Smoking == "current smoker" & !is.na(data$Smoking)] <- 4
data$Smoking <- as.numeric(data$Smoking)

## 술쟁이들
data$Alcohol[data$Alcohol == "never" & !is.na(data$Alcohol)] <- 1
data$Alcohol[data$Alcohol == "social drinker" & !is.na(data$Alcohol)] <- 2
data$Alcohol[data$Alcohol == "drink a lot" & !is.na(data$Alcohol)] <- 3
data$Alcohol <- as.numeric(data$Alcohol)

## 지각쟁이
data$Punctuality[data$Punctuality == "i am often early" & !is.na(data$Punctuality)] <- 1
data$Punctuality[data$Punctuality == "i am always on time" & !is.na(data$Punctuality)] <- 2
data$Punctuality[data$Punctuality == "i am often running late" & !is.na(data$Punctuality)] <- 3
data$Punctuality <- as.numeric(data$Punctuality)

## 구라쟁이
data$Lying[data$Lying == "never" & !is.na(data$Lying)] <- 1
data$Lying[data$Lying == "sometimes" & !is.na(data$Lying)] <- 2
data$Lying[data$Lying == "only to avoid hurting someone" & !is.na(data$Lying)] <- 3
data$Lying[data$Lying == "everytime it suits me" & !is.na(data$Lying)] <- 4
data$Lying <- as.numeric(data$Lying)

## 인터넷쟁이
data$Internet.usage[data$Internet.usage == "no time at all" & !is.na(data$Internet.usage)] <- 1
data$Internet.usage[data$Internet.usage == "less than an hour a day" & !is.na(data$Internet.usage)] <- 2
data$Internet.usage[data$Internet.usage == "few hours a day" & !is.na(data$Internet.usage)] <- 3
data$Internet.usage[data$Internet.usage == "most of the day" & !is.na(data$Internet.usage)] <- 4
data$Internet.usage <- as.numeric(data$Internet.usage)

## 성별
data$Gender[data$Gender == "female" & !is.na(data$Gender)] <- 0
data$Gender[data$Gender == "male" & !is.na(data$Gender)] <- 1
data$Gender <- as.factor(data$Gender)

## 손잡이
data$Left...right.handed[data$Left...right.handed == "right handed" & !is.na(data$Left...right.handed)] <- 0
data$Left...right.handed[data$Left...right.handed == "left handed" & !is.na(data$Left...right.handed)] <- 1
data$Left...right.handed <- as.factor(data$Left...right.handed)

## 교육
data$Education[data$Education == "currently a primary school pupil" & !is.na(data$Education)] <- 1
data$Education[data$Education == "primary school" & !is.na(data$Education)] <- 2
data$Education[data$Education == "secondary school" & !is.na(data$Education)] <- 3
data$Education[data$Education == "college/bachelor degree" & !is.na(data$Education)] <- 4
data$Education[data$Education == "masters degree" & !is.na(data$Education)] <- 5
data$Education[data$Education == "doctorate degree" & !is.na(data$Education)] <- 6
data$Education <- as.factor(data$Education)

## ????
data$Only.child[data$Only.child == "no" & !is.na(data$Only.child)] <- 0
data$Only.child[data$Only.child == "yes" & !is.na(data$Only.child)] <- 1
data$Only.child <- as.factor(data$Only.child)

## 시골 
data$Village...town[data$Village...town == "village" & !is.na(data$Village...town)] <- 0
data$Village...town[data$Village...town == "city" & !is.na(data$Village...town)] <- 1
data$Village...town <- as.factor(data$Village...town)

## 뭐 집 어떻게 생겼는지?
data$House...block.of.flats[data$House...block.of.flats == "block of flats" & !is.na(data$House...block.of.flats)] <- 0
data$House...block.of.flats[data$House...block.of.flats == "house/bungalow" & !is.na(data$House...block.of.flats)] <- 1
data$House...block.of.flats <- as.factor(data$House...block.of.flats)

```


### Missing Value 처리

```{r}
## 가장 많이 사용되는 값으로 처리할 것임.
## getmode 함수 만들기
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

## is.na 값에 getmode 리턴값 넣기 
for (i in 1 :ncol(data)) {
  data[is.na(data[,i]),i] <- getmode(data[,i])
}

sum(colSums(is.na(data)))
```

## Network Analysis 사용할 것임

```{r, warning=FALSE, message=FALSE, fig.align='center', fig.height=12, fig.width=12}

## 데이터 확인
music = data[,1:19]
movies = data[,19:31]
interests = data[,31:46]
hobbies = data[,46:63]
phobias = data[,63:73]
health = data[,73:76]
traits = data[,76:133]
spending = data[,133:140]
demographics = data[,140:150]


## Polychoric Correlations 
## 위키피디아 참조
## self reports나 survey에 많이 사용되는 correlation이라고 함.
## 오늘 알았음

corMat <- cor_auto(traits)

# corrplot(corMat, method="color",
#          type="upper", order="hclust", 
#          addCoef.col = "black", # Add coefficient of correlation
#          tl.col="black", tl.srt=45, #Text label color and rotation
#          # Combine with significance
#          sig.level = 0.01, insig = "blank", 
#          # hide correlation coefficient on the principal diagonal
#          diag=FALSE 
#          )

names <- c(seq(1:ncol(traits)))
names <- as.character(names)

Graph_lasso <- qgraph(corMat, graph = "glasso", layout = "spring", tuning = 0.25,
                     sampleSize = nrow(data), 
                      legend.cex = 0.35, vsize = 3,esize = 7,
                      posCol = "#003399", negCol = "#FF9933",vTrans = 200, nodeNames = colnames(corMat), labels = names)


```


## Positive mind set vs Negative mind set

### Clustering 할거임

#### 50 49 55 32 vs 37 25 48 44


```{r, warning=FALSE, message=FALSE}
## 데이터 따로 빼기
po_na <- traits[,c(50,49,55,32,37,25,48,44)]
po_na_mat <- cor_auto(po_na)
## 혹시 모르니까 correlation Check
corrplot(po_na_mat, method="color",
         type="upper", order="hclust",
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank",
         # hide correlation coefficient on the principal diagonal
         diag=FALSE
         )

po_na_cluster <- kmeans(po_na, centers = 2, nstart = 25)

## 클러스터가 예상대로 진행되었음을 확인.
po_na_cluster$centers

```

## Modeling

### 세팅

```{r}
## 크게 없지만 모델 만들어 보겠음.
## Classification이고 두 개 pos, neg임
## SVM 쓸 거임
data$group <- as.factor(po_na_cluster$cluster)

ind <- createDataPartition(data$group, p = 0.7, list = FALSE)
train <- data[ind,]
test <- data[-ind,]

dim(train)
```

### SVM

```{r}
train_svm <- train
test_svm <- test

## SVM RBF
svm_radial <- best.tune(svm, group ~., data = train_svm, kernel ="radial")
svm_radial

svm_prediction = predict(svm_radial,newdata = test_svm)
confusionMatrix(svm_prediction,test_svm$group)

## SVM Polynomial
svm_poly <- best.tune(svm, group ~., data = train_svm, kernel ="polynomial")
svm_poly

svm_prediction = predict(svm_poly,newdata = test_svm)
confusionMatrix(svm_prediction,test_svm$group)

## SVM Linear
svm_linear <- best.tune(svm, group ~., data = train_svm, kernel ="linear")
svm_linear
svm_prediction = predict(svm_linear,newdata = test_svm)
confusionMatrix(svm_prediction,test_svm$group)

## SVM sigmoid
svm_sigmoid <- best.tune(svm, group ~., data = train_svm, kernel ="sigmoid")
svm_sigmoid
svm_prediction = predict(svm_sigmoid,newdata = test_svm)
confusionMatrix(svm_prediction,test_svm$group)


```

### Random Forest

```{r, fig.width=9, fig.height=7}
# train_rf <- train
# test_rf <- test
# rf1 <- randomForest(x= train_rf[,-151], y = train_rf[,151], importance = TRUE, ntree = 1000)
# rf1
# varImpPlot(rf1)
# 
# # col <- as.data.frame(rf1$importance) %>%
# #   mutate(rowna <- rownames(.)) %>%
# #   filter(MeanDecreaseGini > 4) %>%
# #   select("rowna <- rownames(.)")
# # colnames(col) <- "rowname"
# # as.vector(t(col))
# # 
# # train_rf %>%
# #   select(-one_of(as.vector(t(col))))
# # 
# # train_rf <- train_rf %>%
# #   select(-one_of(as.vector(t(col))))
# # test_rf <- test_rf %>%
# #   select(-one_of(as.vector(t(col))))
# 
# 
# # rf2 <- randomForest(x= train_rf[,-140], y = train_rf[,140], importance = TRUE, ntree = 1000)
# # rf2
# # varImpPlot(rf2)
# 
# 
# set.seed(2348)
# 
# view(train_rf)
# cv10_1 <- createMultiFolds(train_rf[,140], k = 10, times = 10)
# ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10, index = cv10_1)
# 
# set.seed(1234)
# rf.5<- train(x= train_rf[,-151], y = train_rf[,151], method = "rf", tuneLength = 3,ntree = 1000, trControl =ctrl_1)
# rf.5
# 
# pr.rf=predict(rf.5,newdata = test_rf)
# confusionMatrix(pr.rf,test_rf$group)


```

### Network Analysis Following


```{r, warning=FALSE, message=FALSE, fig.align='center', fig.width=9, fig.height=7}

centRes <- centrality(Graph_lasso)

p1 <- qplot(centRes$OutDegree, geom = "histogram") +
  geom_histogram(bins  = 10) + 
  theme_minimal(12) +labs(title = "Node Strength") + xlab("Strength")
s
p2 <- qplot(centRes$Closeness, geom = "histogram") +
  geom_histogram(bins  = 20) + 
  theme_minimal(12) +labs(title = "Node Closeness") + xlab("Closeness")

p3 <- qplot(centRes$Betweenness, geom = "histogram") +
  geom_histogram(bins  = 20) + 
  theme_minimal(12) +labs(title = "Node Betweenness") + xlab("Betweenness")

grid.arrange(p1,p2,p3, nrow = 3)
```


```{r}

```
















